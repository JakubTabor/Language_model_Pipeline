# [Example 2: word embeddings in spacy](https://github.com/JakubTabor/Language_model_Pipeline/blob/main/spacy_word_embeddings_excercise.ipynb)
# First i gonna preprocess text which is in json format, then train different model with it and finally make measurement and visualize results
# This will be preprocessing phase
* I start from checking if there is a class imbalance, but we have perfect class balance
* Next i encode my classes into numbers, i gonna need fully numerical data
* Then i load large model from spacy trained on english words
# And create function that will put the text into the doc, it is nlp object
* Next it iterate through the tokens, removing **stop words and punctuation**
* And it will fill the list with the rest base tokens
* I apply this function on my data and see that it simplified the text
# Next i will do vectorization of the text to make it full numerical
